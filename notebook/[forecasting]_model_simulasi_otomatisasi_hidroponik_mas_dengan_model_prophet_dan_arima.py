# -*- coding: utf-8 -*-
"""[Forecasting] Model Simulasi Otomatisasi HIdroponik mas dengan model Prophet dan Arima

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B18zkT-wToasUJ9E61X1mVwWN-hk6gip

# 1. Business Understanding
- Mengembangkan Model SImulasi Otomatisasi HIdroponik mas dengan model Prophet dan Arima
- Membandingkan 2 Metode Algoritma Prophet dan ARIMA mana yang terbaik dan efektif.
- Mengembangkan Aplikasi Simulasi Hidroponik (HydroSim) untuk mlakukan simulasi otomasisasi hidroponik tanaman selada dengan menggunakan model terbaik

# 2. Data Understanding
"""

import pandas as pd
from sklearn.model_selection import KFold, train_test_split
from sklearn.metrics import mean_squared_error
from prophet import Prophet
from statsmodels.tsa.arima.model import ARIMA
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.stattools import adfuller
from math import sqrt
from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np
from sklearn.model_selection import TimeSeriesSplit, GridSearchCV
from sklearn.pipeline import make_pipeline, Pipeline
from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin
from tabulate import tabulate
from sklearn.metrics import confusion_matrix

"""## Load Dataset"""

df = pd.read_csv("/content/DataTrainSIOHIFull.csv")

df.head()

df.tail()

"""### EDA"""

df.columns

df.info()

# Check missing data

missing_data = pd.DataFrame({'total_missing': df.isnull().sum(),
                             'perc_missing': (df.isnull().sum()/2634)*100})

missing_data

df.describe()

df = df.drop(columns=['Label'])

# Correlation Matrix
cor_matrix = df.corr()
cor_matrix

# Heatmap of the correlation matrix
plt.figure(figsize=(15, 5))
sns.heatmap(cor_matrix, annot=True, cmap='YlGnBu', fmt=".2f", linewidths=0.5)
plt.title("Correlation Matrix")
plt.show()

"""### Visualisasi"""

# Plotting histograms
plt.figure(figsize=(15, 10))

# Histogram for 'temperature'
plt.subplot(3, 3, 1)
sns.histplot(df['temperature'], bins=20, kde=True, color='skyblue')
plt.title('Histogram of Temperature')
plt.xlabel('Temperature')
plt.ylabel('Frequency')

# Histogram for 'humidity'
plt.subplot(3, 3, 2)
sns.histplot(df['humidity'], bins=20, kde=True, color='salmon')
plt.title('Histogram of Humidity')
plt.xlabel('Humidity')
plt.ylabel('Frequency')

# Histogram for 'light'
plt.subplot(3, 3, 3)
sns.histplot(df['light'], bins=20, kde=True, color='green')
plt.title('Histogram of Light')
plt.xlabel('Light')
plt.ylabel('Frequency')

# Histogram for 'pH'
plt.subplot(3, 3, 4)
sns.histplot(df['pH'], bins=20, kde=True, color='purple')
plt.title('Histogram of pH')
plt.xlabel('pH')
plt.ylabel('Frequency')

# Histogram for 'EC'
plt.subplot(3, 3, 5)
sns.histplot(df['EC'], bins=20, kde=True, color='orange')
plt.title('Histogram of EC')
plt.xlabel('EC')
plt.ylabel('Frequency')

# Histogram for 'TDS'
plt.subplot(3, 3, 6)
sns.histplot(df['TDS'], bins=20, kde=True, color='brown')
plt.title('Histogram of TDS')
plt.xlabel('TDS')
plt.ylabel('Frequency')

# Histogram for 'WaterTemp'
plt.subplot(3, 3, 7)
sns.histplot(df['WaterTemp'], bins=20, kde=True, color='pink')
plt.title('Histogram of WaterTemp')
plt.xlabel('WaterTemp')
plt.ylabel('Frequency')

plt.tight_layout()
plt.show()

"""#### Visualisasi Terhadap Hari"""

# Group by 'day' and calculate the mean of 'LeafCount'
average_leaf_count = df.groupby('day')['LeafCount'].mean().reset_index()

# Plotting the data
plt.figure(figsize=(10, 6))
plt.plot(average_leaf_count['day'], average_leaf_count['LeafCount'], marker='o', linestyle='-', color='b')

# Adding titles and labels
plt.title('Average Leaf Count Over Days')
plt.xlabel('Day')
plt.ylabel('Average Leaf Count')

# Display the plot
plt.grid(True)
plt.show()

# Group by 'day' and calculate the mean of 'EC' and 'TDS'
average_values = df.groupby('day')[['EC', 'TDS']].mean().reset_index()

# Creating the subplots
fig, axs = plt.subplots(2, 1, figsize=(10, 10), sharex=True)

# Plotting average EC vs day
axs[0].plot(average_values['day'], average_values['EC'], marker='o', linestyle='-', color='r')
axs[0].set_title('Average EC vs Day')
axs[0].set_ylabel('Average EC')
axs[0].grid(True)

# Plotting average TDS vs day
axs[1].plot(average_values['day'], average_values['TDS'], marker='o', linestyle='-', color='g')
axs[1].set_title('Average TDS vs Day')
axs[1].set_xlabel('Day')
axs[1].set_ylabel('Average TDS')
axs[1].grid(True)

# Displaying the plots
plt.tight_layout()
plt.show()

"""#### Visualisasi dengan Jumlah Daun"""

# Plotting EC vs TDS with LeafCount as marker size
plt.figure(figsize=(10, 6))
plt.scatter(df['EC'], df['TDS'], s=df['LeafCount']*10, alpha=0.5, c='blue', label='LeafCount')
plt.title('EC and TDS vs LeafCount')
plt.xlabel('EC')
plt.ylabel('TDS')
plt.colorbar(label='LeafCount')
plt.legend()

plt.grid(True)
plt.show()

"""# 3. Data Preparation"""

df.info()

df_copy = df.copy()

df_copy['time']

# Tambahkan "0" di depan nilai yang hanya satu digit di bagian jam
df_copy['time'] = df_copy['time'].apply(lambda x: '{:.2f}'.format(x))

# Konversi 'time' ke format waktu yang benar
df_copy['time'] = pd.to_datetime(df_copy['time'], format='%H.%M').dt.time

df_copy

df_copy.columns

df_prep = df_copy.copy()

df_prep = df_prep[['day', 'time', 'LeafCount']]

df_prep.info()

print(df_prep)

# Tentukan tanggal awal
start_date = pd.to_datetime('2024-01-01')

# Ubah kolom 'time' menjadi string
df_prep['time'] = df_prep['time'].astype(str)

# Buat kolom 'datetime' dengan menambahkan 'day' ke tanggal awal dan menggabungkan dengan 'time'
df_prep['datetime'] = df_prep.apply(lambda row: start_date + pd.Timedelta(days=row['day'] - 1) + pd.to_timedelta(row['time']), axis=1)

print(df_prep.head())

"""### Data Pre-Processing"""

# Convert to correct data types
df_prep['day'] = df_prep['day'].astype(int)
df_prep['time'] = df_prep['time'].astype(str)
df_prep['LeafCount'] = df_prep['LeafCount'].astype(int)

# Convert to correct data types
df_copy['day'] = df_copy['day'].astype(int)
df_copy['time'] = df_copy['time'].astype(str)
df_copy['LeafCount'] = df_copy['LeafCount'].astype(int)

# Merge the 'datetime' column from df_prep into df_copy
df_model = pd.merge(df_copy, df_prep[['day', 'time', 'LeafCount', 'datetime']], on=['day', 'time', 'LeafCount'], how='inner')

# Debug: Check the result of the merge
print("df_model after merge:")
print(df_model.head())

# Set the 'datetime' column as the index and sort it
df_model.set_index('datetime', inplace=True)
df_model = df_model.sort_index()

df_model.duplicated().sum()

# Remove duplicate rows
df_model = df_model.drop_duplicates()

# Debug: Check the number of duplicates after removal
print(f"Number of duplicates after removal: {df_model.duplicated().sum()}")

# Ensure that the data is sorted by datetime
df_model = df_model.sort_index()

# Split the data into training (80%) and testing (20%) sets
train_size = int(len(df_model) * 0.8)
train, test = df_model.iloc[:train_size], df_model.iloc[train_size:]

# Debug: Check the split
print(f"Training set length: {len(train)}")
print(f"Test set length: {len(test)}")

"""# Modelling

## ARIMA Model
"""

# Select the 'LeafCount' column as the target variable
train_leafcount = train['LeafCount']
test_leafcount = test['LeafCount']

# Fit the ARIMA model on the training data
arima_order = (5, 1, 0)  # Example order, you may need to adjust this based on AIC/BIC criteria
arima_model = ARIMA(train_leafcount, order=arima_order)
arima_fit = arima_model.fit()

# Make predictions on the test set
predictions_arima = arima_fit.forecast(steps=len(test_leafcount))

# Calculate RMSE and MAE for ARIMA
rmse_arima = np.sqrt(mean_squared_error(test_leafcount, predictions_arima))
mae_arima = mean_absolute_error(test_leafcount, predictions_arima)

print(f"ARIMA RMSE: {rmse_arima}")
print(f"ARIMA MAE: {mae_arima}")

# Plot the results
plt.figure(figsize=(15, 8))
plt.plot(train.index, train_leafcount, label='Training Data')
plt.plot(test.index, test_leafcount, label='Test Data')
plt.plot(test.index, predictions_arima, label='Predictions', color='red')
plt.xlabel('Date')
plt.ylabel('Leaf Count')
plt.legend()
plt.show()

"""## Prophet Model"""

# Prepare data for Prophet
train_prophet = train.reset_index()[['datetime', 'LeafCount']].rename(columns={'datetime': 'ds', 'LeafCount': 'y'})
test_prophet = test.reset_index()[['datetime', 'LeafCount']].rename(columns={'datetime': 'ds', 'LeafCount': 'y'})

# Initialize and fit Prophet model
prophet_model = Prophet()
prophet_model.fit(train_prophet)

# Make predictions on the test set
future = test_prophet[['ds']]
forecast = prophet_model.predict(future)
predictions_prophet = forecast['yhat'].values

# Calculate RMSE and MAE for Prophet
rmse_prophet = np.sqrt(mean_squared_error(test_prophet['y'], predictions_prophet))
mae_prophet = mean_absolute_error(test_prophet['y'], predictions_prophet)

print(f"Prophet RMSE: {rmse_prophet}")
print(f"Prophet MAE: {mae_prophet}")

# Plot the results
plt.figure(figsize=(15, 8))
plt.plot(train_prophet['ds'], train_prophet['y'], label='Training Data')
plt.plot(test_prophet['ds'], test_prophet['y'], label='Test Data')
plt.plot(test_prophet['ds'], predictions_prophet, label='Prophet Predictions', color='red')
plt.xlabel('Date')
plt.ylabel('Leaf Count')
plt.legend()
plt.show()

"""## Compare the Models"""

# Print the comparison of RMSE and MAE
print("Comparison of Forecasting Models (ARIMA vs Prophet):\n")
print(f"{'Metric':<25} {'ARIMA':<15} {'Prophet':<15} {'Improvement':<15}")
print("="*70)
print(f"{'RMSE':<25} {rmse_arima:<15.4f} {rmse_prophet:<15.4f} {(rmse_arima - rmse_prophet):<15.4f}")
print(f"{'MAE':<25} {mae_arima:<15.4f} {mae_prophet:<15.4f} {(mae_arima - mae_prophet):<15.4f}")
print("="*70)

"""# Fine-Tuning

## ARIMA Models

### Define the K-Fold, Hyperparamter Grid and Split Data
"""

# Split data into features (X) and target (y)
X = df_model[['temperature', 'humidity', 'light', 'pH', 'EC', 'TDS', 'WaterTemp']]  # Example features
y = df_model['LeafCount']

# Initialize TimeSeriesSplit for K-Fold Cross-Validation
tscv = TimeSeriesSplit(n_splits=5)

# Define ranges for ARIMA hyperparameters
p_values = range(0, 3)  # Example range for p
d_values = range(0, 2)  # Example range for d
q_values = range(0, 3)  # Example range for q

"""### K-Fold Cross-Validation and Hyperparameter Tunning"""

# Initialize variables to store best model parameters and metrics
best_score = float('inf')
best_params = None
results = []

# Perform K-Fold Cross-Validation and Hyperparameter Tuning
for p in p_values:
    for d in d_values:
        for q in q_values:
            mse_scores = []

            for train_index, val_index in tscv.split(X):
                # Split data
                X_train, X_val = X.iloc[train_index], X.iloc[val_index]
                y_train, y_val = y.iloc[train_index], y.iloc[val_index]

                # Fit ARIMA model
                arima_model = ARIMA(y_train, order=(p, d, q))
                arima_fit = arima_model.fit()

                # Make predictions
                predictions = arima_fit.forecast(steps=len(y_val))

                # Calculate MSE
                mse = mean_squared_error(y_val, predictions)
                mse_scores.append(mse)

            # Calculate average MSE across folds
            avg_mse = np.mean(mse_scores)

            # Record results
            results.append({
                'p': p,
                'd': d,
                'q': q,
                'Average MSE': avg_mse
            })

            # Check if this is the best model so far
            if avg_mse < best_score:
                best_score = avg_mse
                best_params = (p, d, q)

# Convert results to DataFrame for easier visualization
results_df = pd.DataFrame(results)

# Sort results by Average MSE
results_df = results_df.sort_values(by='Average MSE')

# Print the results table
print("ARIMA Model Evaluation Results:\n")
print(results_df.to_string(index=False))
print("\nBest ARIMA Model:")
print(f"Parameters: order = {best_params}, Average MSE = {best_score}")

"""### Train Hyperparamter Model"""

# Additional features (X) and target variable (y)
X = df_model[['temperature', 'humidity', 'light', 'pH', 'EC', 'TDS', 'WaterTemp']]  # Example features
y = df_model['LeafCount']

# Initialize TimeSeriesSplit for K-fold cross-validation
n_splits = 5  # Number of splits (adjust as needed)
tscv = TimeSeriesSplit(n_splits=n_splits)

# Define function to calculate RMSE and MSE
def calculate_metrics(y_true, y_pred):
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mse = mean_squared_error(y_true, y_pred)
    return rmse, mse

# Lists to store evaluation metrics
arima_train_rmse = []
arima_train_mse = []
arima_test_rmse = []
arima_test_mse = []

# Perform K-fold cross-validation for ARIMA model
for train_index, test_index in tscv.split(df_model):
    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

    # Initialize ARIMA model and fit on training data
    arima_model = ARIMA(endog=y_train, exog=X_train, order=(2, 1, 0))
    arima_fit = arima_model.fit()

    # Make predictions on training set
    arima_train_pred = arima_fit.predict(start=train_index[0], end=train_index[-1], exog=X_train, typ='levels')
    arima_train_rmse_i, arima_train_mse_i = calculate_metrics(y_train, arima_train_pred)
    arima_train_rmse.append(arima_train_rmse_i)
    arima_train_mse.append(arima_train_mse_i)

    # Make predictions on test set
    arima_test_pred = arima_fit.predict(start=test_index[0], end=test_index[-1], exog=X_test, typ='levels')
    arima_test_rmse_i, arima_test_mse_i = calculate_metrics(y_test, arima_test_pred)
    arima_test_rmse.append(arima_test_rmse_i)
    arima_test_mse.append(arima_test_mse_i)

# Print average RMSE and MSE for ARIMA model
print("ARIMA Model with Additional Features:")
print(f"Average Train RMSE: {np.mean(arima_train_rmse)}")
print(f"Average Train MSE: {np.mean(arima_train_mse)}")
print(f"Average Test RMSE: {np.mean(arima_test_rmse)}")
print(f"Average Test MSE: {np.mean(arima_test_mse)}")

# Fit ARIMA model with best parameters (order=(2, 1, 0)) on training set
arima_model = ARIMA(y_train, order=(2, 1, 0))
arima_fit = arima_model.fit()

# Make predictions on the test set
y_pred = arima_fit.predict(start=len(y_train), end=len(y_train) + len(y_test) - 1, typ='levels')

# Calculate RMSE and MSE on the test set
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mse = mean_squared_error(y_test, y_pred)

print(f"Test RMSE: {rmse}")
print(f"Test MSE: {mse}")

# Example data (replace with your actual data)
train = df_model[:train_size]
test = df_model[train_size:]

# Example columns (replace with your actual columns)
train_leafcount = train['LeafCount']
test_leafcount = test['LeafCount']

# Plot the results
plt.figure(figsize=(15, 8))
plt.plot(train.index, train_leafcount, label='Training Data')
plt.plot(test.index, test_leafcount, label='Test Data')
plt.plot(test.index, predictions_arima, label='Predictions', color='red')
plt.xlabel('Date')
plt.ylabel('Leaf Count')
plt.title('ARIMA Model Predictions vs Actual Data')
plt.legend()
plt.show()

"""## Prophet Model

### Define and Initialize
"""

# Initialize TimeSeriesSplit for K-fold cross-validation
n_splits = 5  # Number of splits (adjust as needed)
tscv = TimeSeriesSplit(n_splits=n_splits)

# Define function to calculate RMSE and MSE
def calculate_metrics(y_true, y_pred):
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mse = mean_squared_error(y_true, y_pred)
    return rmse, mse

# Lists to store evaluation metrics
prophet_train_rmse = []
prophet_train_mse = []
prophet_test_rmse = []
prophet_test_mse = []

"""### K-Fold Cross-Validation"""

# Perform K-fold cross-validation for Prophet model
for train_index, test_index in tscv.split(df_model):
    train_data = df_model.iloc[train_index]
    test_data = df_model.iloc[test_index]

    # Prepare data for Prophet
    train_prophet = train_data.reset_index()[['datetime', 'LeafCount']].rename(columns={'datetime': 'ds', 'LeafCount': 'y'})
    test_prophet = test_data.reset_index()[['datetime', 'LeafCount']].rename(columns={'datetime': 'ds', 'LeafCount': 'y'})

    # Initialize Prophet model and fit on training data
    prophet_model = Prophet()
    prophet_model.fit(train_prophet)

    # Make predictions on training set
    prophet_train_forecast = prophet_model.predict(train_prophet)
    prophet_train_pred = prophet_train_forecast['yhat'].values
    prophet_train_rmse_i, prophet_train_mse_i = calculate_metrics(train_prophet['y'], prophet_train_pred)
    prophet_train_rmse.append(prophet_train_rmse_i)
    prophet_train_mse.append(prophet_train_mse_i)

    # Make predictions on test set
    prophet_test_forecast = prophet_model.predict(test_prophet)
    prophet_test_pred = prophet_test_forecast['yhat'].values
    prophet_test_rmse_i, prophet_test_mse_i = calculate_metrics(test_prophet['y'], prophet_test_pred)
    prophet_test_rmse.append(prophet_test_rmse_i)
    prophet_test_mse.append(prophet_test_mse_i)

# Print average RMSE and MSE for Prophet model
print("Prophet Model:")
print(f"Average Train RMSE: {np.mean(prophet_train_rmse)}")
print(f"Average Train MSE: {np.mean(prophet_train_mse)}")
print(f"Average Test RMSE: {np.mean(prophet_test_rmse)}")
print(f"Average Test MSE: {np.mean(prophet_test_mse)}")

"""# Evaluation"""

# Define the results in a list of lists format
results = [
    ["Prophet Model",
     np.mean(prophet_train_rmse), np.mean(prophet_train_mse),
     np.mean(prophet_test_rmse), np.mean(prophet_test_mse)],
    ["ARIMA Model",
     np.mean(arima_train_rmse), np.mean(arima_train_mse),
     np.mean(arima_test_rmse), np.mean(arima_test_mse)]
]

# Define headers for the table
headers = ["Model", "Average Train RMSE", "Average Train MSE", "Average Test RMSE", "Average Test MSE"]

# Print the table
print(tabulate(results, headers=headers, tablefmt="pretty"))

"""# Deployment"""

# Prepare data for Prophet
train_prophet = train.reset_index()[['datetime', 'LeafCount']].rename(columns={'datetime': 'ds', 'LeafCount': 'y'})
test_prophet = test.reset_index()[['datetime', 'LeafCount']].rename(columns={'datetime': 'ds', 'LeafCount': 'y'})

# Ensure datetime column is accessible after resetting index
train_prophet = train.reset_index()[['datetime', 'LeafCount']].rename(columns={'datetime': 'ds', 'LeafCount': 'y'})
test_prophet = test.reset_index()[['datetime', 'LeafCount']].rename(columns={'datetime': 'ds', 'LeafCount': 'y'})

# Initialize Prophet model
prophet_model = Prophet()

# Fit Prophet model on training data
prophet_model.fit(train_prophet)

num_days_to_forecast = 5  # User input for number of days to forecast

# Forecast for the next num_days_to_forecast days
future_dates = prophet_model.make_future_dataframe(periods=num_days_to_forecast, freq='D')
forecast = prophet_model.predict(future_dates)

# Extract forecasted dates and values
forecast_dates = forecast['ds'].tail(num_days_to_forecast)
forecast_values = forecast['yhat'].tail(num_days_to_forecast)

# Display the forecasted values
forecast_df = pd.DataFrame({'Date': forecast_dates, 'Forecasted_LeafCount': forecast_values})
print(f"Forecasting for the next {num_days_to_forecast} days:")
print(forecast_df)

# Plot the results
plt.figure(figsize=(15, 8))

# Training data
plt.plot(train.index, train['LeafCount'], label='Training Data', marker='o', linestyle='-', color='blue')

# Test data (actual values)
plt.plot(test.index, test['LeafCount'], label='Test Data', marker='o', linestyle='-', color='green')

# Forecasted values
plt.plot(forecast_df['Date'], forecast_df['Forecasted_LeafCount'], label='Forecasted', marker='o', linestyle='-', color='red')

plt.xlabel('Date')
plt.ylabel('Leaf Count')
plt.title('Prophet Model Forecast vs Actual')
plt.legend()
plt.grid(True)
plt.show()