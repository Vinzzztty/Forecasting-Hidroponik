# -*- coding: utf-8 -*-
"""[Confusion Matrix] Pattern Pertumbuhan Selada

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vXWDc6ELpQZhd_Z5InXOXsF1R7tQ6ru6
"""

"""Data Preparation Library"""
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, KFold, GridSearchCV
import numpy as np

"""Models Library"""
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import mean_squared_error
from sklearn.svm import SVC, SVR
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor

"""Model Evaluation"""
from sklearn.model_selection import cross_val_score
from tabulate import tabulate

"""Other"""
import warnings
from sklearn.utils._testing import ignore_warnings
from sklearn.exceptions import ConvergenceWarning
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category = ConvergenceWarning)

# Load dataset
df = pd.read_csv("Dataset_v2.csv")

# First 5 rows of data
df.head()

df = df.drop(columns=['Jam', 'Label'])

df.head()

# Tentukan kolom yang akan dipertimbangkan
kolom_yang_dipertimbangkan = ['temperature', 'humidity', 'light', 'pH', 'EC', 'TDS', 'WaterTemp']

# Hitung IQR untuk kolom-kolom yang sudah ditentukan
Q1 = df[kolom_yang_dipertimbangkan].quantile(0.25)
Q3 = df[kolom_yang_dipertimbangkan].quantile(0.75)
IQR = Q3 - Q1

# Filter outlier untuk kolom-kolom yang sudah ditentukan
insurance = df[~((df[kolom_yang_dipertimbangkan] < (Q1 - 1.5 * IQR)) | (df[kolom_yang_dipertimbangkan] > (Q3 + 1.5 * IQR))).any(axis=1)]

# Periksa ukuran dataset setelah menghapus outlier
insurance.shape

# Correlation Matrix
cor_matrix = df.corr()
cor_matrix

# Heatmap of the correlation matrix
plt.figure(figsize=(15, 5))
sns.heatmap(cor_matrix, annot=True, cmap='YlGnBu', fmt=".2f", linewidths=0.5)
plt.title("Correlation Matrix")
plt.show()

# Membuat fitur-fitur yang akan digunakan
fitur = ['temperature', 'humidity', 'light', 'pH', 'EC', 'TDS', 'WaterTemp']

# Mengganti nilai-nilai dalam DataFrame
X = df[fitur]

# Variabel Target
y = df['Pattern']

# Memisahkan data menjadi data latih dan data uji dengan perbandingan 80% dan 20%
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Memeriksa kolom-kolom non-numeric
kolom_non_numerik = X.select_dtypes(exclude=['float64', 'int64']).columns
print("Kolom non-numeric:", kolom_non_numerik)

# Standard Scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Define the Gradient Boosting Classifier with specified parameters
model = GradientBoostingClassifier(learning_rate=0.1, max_depth=10)

# Train the model
model.fit(X_train, y_train)

# Predict on training and testing sets
y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)

# Evaluation metrics on training set
print("Training Set Metrics:")
print("Accuracy:", accuracy_score(y_train, y_train_pred))
print("Precision:", precision_score(y_train, y_train_pred, average='weighted'))
print("Recall:", recall_score(y_train, y_train_pred, average='weighted'))
print("F1 Score:", f1_score(y_train, y_train_pred, average='weighted'))

# Evaluation metrics on testing set
print("\nTesting Set Metrics:")
print("Accuracy:", accuracy_score(y_test, y_test_pred))
print("Precision:", precision_score(y_test, y_test_pred, average='weighted'))
print("Recall:", recall_score(y_test, y_test_pred, average='weighted'))
print("F1 Score:", f1_score(y_test, y_test_pred, average='weighted'))

# Confusion matrix
conf_mat = confusion_matrix(y_test, y_test_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=model.classes_, yticklabels=model.classes_)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

features = ['temperature', 'humidity', 'light', 'pH', 'EC', 'TDS', 'WaterTemp']

# Function to get user input and make prediction
def predict_pattern(model, features):
    # Initialize empty dictionary to store user input
    user_input = {}

    # Prompt user for input for each feature
    for feature in features:
        user_input[feature] = float(input(f"Enter {feature}: "))

    # Create a DataFrame with user input
    input_data = pd.DataFrame([user_input])

    # Make prediction using the trained model
    prediction = model.predict(input_data)

    return prediction[0]

# Example usage:
if __name__ == "__main__":
    # Prompt user for input and make prediction
    predicted_pattern = predict_pattern(model, features)

    print(f"\nPredicted Pattern: {predicted_pattern}")